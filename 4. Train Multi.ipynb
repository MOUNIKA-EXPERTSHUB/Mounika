{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (27401, 32, 32, 1) (27401, 6)\n",
      "Validation set (6000, 32, 32, 1) (6000, 6)\n",
      "Test set (13068, 32, 32, 1) (13068, 6)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN_multi_crop.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy_single(predictions, labels):\n",
    "    \"\"\"calculate character-level accuracy\"\"\"\n",
    "    a = np.argmax(predictions, 2).T == labels[:,1:6]\n",
    "    length = labels[:,0]\n",
    "    summ = 0.0\n",
    "    for i in range(len(length)):\n",
    "        summ += np.sum(a[i,:length[i]])\n",
    "    return(100 * summ / np.sum(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_multi(predictions, labels):\n",
    "    \"\"\"calculate sequence-level accuracy\"\"\"\n",
    "    count = predictions.shape[1]\n",
    "    return 100.0 * (count - np.sum([1 for i in np.argmax(predictions, 2).T == labels[:,1:6] if False in i])) / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             28 * 28 * 16  \n",
    "max pooling:         14 * 14 * 16  \n",
    "conv_2:              10 * 10 * 32  \n",
    "max_pooling:         5 * 5 * 32  \n",
    "conv_3:              1 * 1 * 64  \n",
    "\n",
    "dropout              0.9375  \n",
    "sw_1:                64 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 64\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "#     layer1_weights = weight_varible([patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_weights = tf.get_variable('W1',shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "#     layer2_weights = weight_varible([patch_size, patch_size, depth1, depth2]) # in depth1, out depth2\n",
    "    layer2_weights = tf.get_variable('W2',shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "#     layer3_weights = weight_varible([patch_size, patch_size, depth2, depth3]) # in depth2, out depth3\n",
    "    layer3_weights = tf.get_variable('W3',shape=[patch_size, patch_size, depth2, depth3],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "\n",
    "    s1_w = tf.get_variable(\"WS1\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s1_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS1')\n",
    "    s2_w = tf.get_variable(\"WS2\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s2_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS2')\n",
    "    s3_w = tf.get_variable(\"WS3\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s3_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS3')\n",
    "    s4_w = tf.get_variable(\"WS4\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s4_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS4')\n",
    "    s5_w = tf.get_variable(\"WS5\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    s5_b = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='BS5')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 28 * 28 * depth1\n",
    "        pool1 = max_pooling(hidden1) # 14 * 14 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 10 * 10 * depth2\n",
    "        pool2 = max_pooling(hidden2) # 5 * 5 * depth2\n",
    "        # conv3 layer 3\n",
    "        pool3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 1 * 1 * depth3\n",
    "#         pool3 = max_pooling(hidden3) # 1 * 1 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "        hidden4_drop = tf.nn.dropout(pool3_flat, 0.9375)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "# Training computation.\n",
    "    logits = model(tf_train_dataset)\n",
    "    [logits_1, logits_2, logits_3, logits_4, logits_5] = model(tf_train_dataset)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "    \n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.05, global_step, 1000, 0.70, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 16.209852\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 500: 5.981581\n",
      "Minibatch accuracy: 1.6%\n",
      "Validation accuracy: 3.3%\n",
      "Minibatch loss at step 1000: 5.648309\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 4.0%\n",
      "Minibatch loss at step 1500: 4.760007\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 8.3%\n",
      "Minibatch loss at step 2000: 4.746642\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 12.1%\n",
      "Minibatch loss at step 2500: 4.075912\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 13.9%\n",
      "Minibatch loss at step 3000: 4.167899\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 14.8%\n",
      "Minibatch loss at step 3500: 4.798819\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 15.6%\n",
      "Minibatch loss at step 4000: 3.603654\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 17.2%\n",
      "Minibatch loss at step 4500: 4.381269\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 18.0%\n",
      "Minibatch loss at step 5000: 3.754035\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 19.3%\n",
      "Minibatch loss at step 5500: 3.747772\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 18.8%\n",
      "Minibatch loss at step 6000: 4.115950\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 19.6%\n",
      "Minibatch loss at step 6500: 3.337996\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 19.8%\n",
      "Minibatch loss at step 7000: 4.712622\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 19.6%\n",
      "Minibatch loss at step 7500: 4.018486\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 20.0%\n",
      "Minibatch loss at step 8000: 4.053636\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 20.2%\n",
      "Minibatch loss at step 8500: 4.623911\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 19.9%\n",
      "Minibatch loss at step 9000: 4.566420\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 20.3%\n",
      "Minibatch loss at step 9500: 3.844863\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 21.4%\n",
      "Minibatch loss at step 10000: 4.044575\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 20.9%\n",
      "Minibatch loss at step 10500: 5.038891\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 20.6%\n",
      "Minibatch loss at step 11000: 4.275420\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 11500: 3.244489\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 20.2%\n",
      "Minibatch loss at step 12000: 3.750882\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 20.5%\n",
      "Minibatch loss at step 12500: 3.607154\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 13000: 4.073824\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 13500: 3.785114\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 21.4%\n",
      "Minibatch loss at step 14000: 4.022429\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 20.7%\n",
      "Minibatch loss at step 14500: 4.089881\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 21.0%\n",
      "Minibatch loss at step 15000: 3.778785\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 20.4%\n",
      "Minibatch loss at step 15500: 3.962036\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 16000: 4.217130\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 21.6%\n",
      "Minibatch loss at step 16500: 3.757998\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 20.6%\n",
      "Minibatch loss at step 17000: 3.238073\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 17500: 4.101058\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 21.2%\n",
      "Minibatch loss at step 18000: 4.521956\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 18500: 3.987187\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 21.0%\n",
      "Minibatch loss at step 19000: 3.944113\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 21.1%\n",
      "Minibatch loss at step 19500: 3.407408\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 20.9%\n",
      "Minibatch loss at step 20000: 3.857526\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 21.2%\n",
      "Test accuracy: 22.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "max pooling:         16 * 16 * 16  \n",
    "conv_2:              16* 16 * 32  \n",
    "max_pooling:         8 * 8 * 32  \n",
    "conv_3:              8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.9375  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[image_size // 8 * image_size // 8 * depth3, num_hidden])\n",
    "    layer4_biases = bias_varible([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "# Training computation.\n",
    "    logits = model(tf_train_dataset, 0.9375)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 19.218676\n",
      "Minibatch single digit accuracy: 5.4%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 18.3%\n",
      "Validation image accuracy: 1.3%\n",
      "Minibatch loss at step 500: 4.821128\n",
      "Minibatch single digit accuracy: 32.4%\n",
      "Minibatch image accuracy: 12.5%\n",
      "Validation single digit accuracy: 37.5%\n",
      "Validation image accuracy: 16.7%\n",
      "Minibatch loss at step 1000: 2.653456\n",
      "Minibatch single digit accuracy: 60.8%\n",
      "Minibatch image accuracy: 46.9%\n",
      "Validation single digit accuracy: 65.2%\n",
      "Validation image accuracy: 49.5%\n",
      "Minibatch loss at step 1500: 1.684686\n",
      "Minibatch single digit accuracy: 80.0%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 73.1%\n",
      "Validation image accuracy: 58.9%\n",
      "Minibatch loss at step 2000: 1.625933\n",
      "Minibatch single digit accuracy: 77.5%\n",
      "Minibatch image accuracy: 64.1%\n",
      "Validation single digit accuracy: 75.5%\n",
      "Validation image accuracy: 62.5%\n",
      "Minibatch loss at step 2500: 0.746641\n",
      "Minibatch single digit accuracy: 91.2%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 75.9%\n",
      "Validation image accuracy: 62.8%\n",
      "Minibatch loss at step 3000: 0.930193\n",
      "Minibatch single digit accuracy: 93.5%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 77.1%\n",
      "Validation image accuracy: 62.7%\n",
      "Minibatch loss at step 3500: 0.807635\n",
      "Minibatch single digit accuracy: 90.4%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 76.3%\n",
      "Validation image accuracy: 62.0%\n",
      "Minibatch loss at step 4000: 0.282140\n",
      "Minibatch single digit accuracy: 99.2%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 76.8%\n",
      "Validation image accuracy: 64.2%\n",
      "Minibatch loss at step 4500: 0.557138\n",
      "Minibatch single digit accuracy: 95.7%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 75.8%\n",
      "Validation image accuracy: 61.9%\n",
      "Minibatch loss at step 5000: 0.458212\n",
      "Minibatch single digit accuracy: 94.3%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 77.3%\n",
      "Validation image accuracy: 64.2%\n",
      "Minibatch loss at step 5500: 0.323312\n",
      "Minibatch single digit accuracy: 95.6%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 78.0%\n",
      "Validation image accuracy: 64.5%\n",
      "Minibatch loss at step 6000: 0.304077\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 65.3%\n",
      "Minibatch loss at step 6500: 0.161779\n",
      "Minibatch single digit accuracy: 97.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 77.1%\n",
      "Validation image accuracy: 63.8%\n",
      "Minibatch loss at step 7000: 0.368362\n",
      "Minibatch single digit accuracy: 96.8%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 76.6%\n",
      "Validation image accuracy: 63.7%\n",
      "Minibatch loss at step 7500: 0.251682\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 76.8%\n",
      "Validation image accuracy: 63.3%\n",
      "Minibatch loss at step 8000: 0.396552\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 78.2%\n",
      "Validation image accuracy: 65.2%\n",
      "Minibatch loss at step 8500: 0.389750\n",
      "Minibatch single digit accuracy: 95.9%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 78.5%\n",
      "Validation image accuracy: 65.3%\n",
      "Minibatch loss at step 9000: 0.384582\n",
      "Minibatch single digit accuracy: 96.4%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 77.8%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 9500: 0.150732\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 65.0%\n",
      "Minibatch loss at step 10000: 0.193874\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 64.7%\n",
      "Minibatch loss at step 10500: 0.218849\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.3%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 11000: 0.108967\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 79.2%\n",
      "Validation image accuracy: 67.3%\n",
      "Minibatch loss at step 11500: 0.173750\n",
      "Minibatch single digit accuracy: 97.7%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 12000: 0.106012\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 78.9%\n",
      "Validation image accuracy: 66.4%\n",
      "Minibatch loss at step 12500: 0.098109\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 65.6%\n",
      "Minibatch loss at step 13000: 0.418334\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 65.1%\n",
      "Minibatch loss at step 13500: 0.290863\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.0%\n",
      "Validation image accuracy: 66.2%\n",
      "Minibatch loss at step 14000: 0.146936\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 79.1%\n",
      "Validation image accuracy: 67.0%\n",
      "Minibatch loss at step 14500: 0.315580\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 65.7%\n",
      "Minibatch loss at step 15000: 0.149370\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 66.2%\n",
      "Minibatch loss at step 15500: 0.360492\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 78.5%\n",
      "Validation image accuracy: 65.6%\n",
      "Minibatch loss at step 16000: 0.122609\n",
      "Minibatch single digit accuracy: 99.2%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 78.9%\n",
      "Validation image accuracy: 66.3%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-3761c58b0468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_regul\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         _, l, predictions = session.run(\n\u001b[0;32m---> 13\u001b[0;31m           [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minibatch loss at step %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/RyanG/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model v1 - Change Dropout"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "max pooling:         16 * 16 * 16  \n",
    "conv_2:              16* 16 * 32  \n",
    "max_pooling:         8 * 8 * 32  \n",
    "conv_3:              8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.5  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[image_size // 8 * image_size // 8 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.80, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 30.106844\n",
      "Minibatch single digit accuracy: 4.1%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 18.3%\n",
      "Validation image accuracy: 1.3%\n",
      "Minibatch loss at step 500: 5.182123\n",
      "Minibatch single digit accuracy: 27.6%\n",
      "Minibatch image accuracy: 9.4%\n",
      "Validation single digit accuracy: 33.1%\n",
      "Validation image accuracy: 11.3%\n",
      "Minibatch loss at step 1000: 2.731842\n",
      "Minibatch single digit accuracy: 67.1%\n",
      "Minibatch image accuracy: 53.1%\n",
      "Validation single digit accuracy: 64.2%\n",
      "Validation image accuracy: 49.1%\n",
      "Minibatch loss at step 1500: 1.559345\n",
      "Minibatch single digit accuracy: 80.7%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 73.2%\n",
      "Validation image accuracy: 60.0%\n",
      "Minibatch loss at step 2000: 1.872497\n",
      "Minibatch single digit accuracy: 76.8%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 75.7%\n",
      "Validation image accuracy: 63.6%\n",
      "Minibatch loss at step 2500: 1.323040\n",
      "Minibatch single digit accuracy: 87.6%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 76.7%\n",
      "Validation image accuracy: 65.1%\n",
      "Minibatch loss at step 3000: 1.700884\n",
      "Minibatch single digit accuracy: 84.2%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 67.1%\n",
      "Minibatch loss at step 3500: 1.147533\n",
      "Minibatch single digit accuracy: 89.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 79.9%\n",
      "Validation image accuracy: 68.9%\n",
      "Minibatch loss at step 4000: 0.497219\n",
      "Minibatch single digit accuracy: 93.3%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 80.7%\n",
      "Validation image accuracy: 70.0%\n",
      "Minibatch loss at step 4500: 0.749898\n",
      "Minibatch single digit accuracy: 94.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 80.1%\n",
      "Validation image accuracy: 68.9%\n",
      "Minibatch loss at step 5000: 0.653584\n",
      "Minibatch single digit accuracy: 95.0%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 80.5%\n",
      "Validation image accuracy: 69.9%\n",
      "Minibatch loss at step 5500: 0.484961\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 81.2%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 6000: 0.604981\n",
      "Minibatch single digit accuracy: 96.6%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 6500: 0.350257\n",
      "Minibatch single digit accuracy: 97.6%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 70.7%\n",
      "Minibatch loss at step 7000: 0.808345\n",
      "Minibatch single digit accuracy: 96.1%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 81.5%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 7500: 0.344865\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 81.9%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 8000: 0.215929\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 81.2%\n",
      "Validation image accuracy: 70.9%\n",
      "Minibatch loss at step 8500: 0.451732\n",
      "Minibatch single digit accuracy: 98.0%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 81.7%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 9000: 0.379113\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 9500: 0.192198\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 72.1%\n",
      "Minibatch loss at step 10000: 0.291765\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 10500: 0.263691\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 71.9%\n",
      "Minibatch loss at step 11000: 0.236802\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 11500: 0.203675\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 12000: 0.151470\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 12500: 0.149923\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 13000: 0.261009\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 13500: 0.204084\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 14000: 0.171580\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 14500: 0.146198\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.4%\n",
      "Validation image accuracy: 72.4%\n",
      "Minibatch loss at step 15000: 0.156922\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 72.6%\n",
      "Test single digit accuracy: 81.3%\n",
      "Test image accuracy: 71.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model v2 -  LRN - Local Response Normalization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "lrn                  32 * 32 * 16\n",
    "max pooling:         16 * 16 * 16 \n",
    "\n",
    "conv_2:              16* 16 * 32 \n",
    "lrn                  16* 16 * 32\n",
    "max_pooling:         8 * 8 * 32  \n",
    "\n",
    "conv_3:              8 * 8 * 64\n",
    "lrn                  8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.5  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[image_size // 8 * image_size // 8 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.80, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset, shape):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset, 1.0)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset, 1.0)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset, 1.0)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 13.347601\n",
      "Minibatch single digit accuracy: 9.5%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 500: 5.714209\n",
      "Minibatch single digit accuracy: 16.6%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 20.8%\n",
      "Validation image accuracy: 3.7%\n",
      "Minibatch loss at step 1000: 3.024511\n",
      "Minibatch single digit accuracy: 60.8%\n",
      "Minibatch image accuracy: 45.3%\n",
      "Validation single digit accuracy: 59.9%\n",
      "Validation image accuracy: 42.4%\n",
      "Minibatch loss at step 1500: 1.887626\n",
      "Minibatch single digit accuracy: 79.3%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 71.9%\n",
      "Validation image accuracy: 58.0%\n",
      "Minibatch loss at step 2000: 2.053926\n",
      "Minibatch single digit accuracy: 78.2%\n",
      "Minibatch image accuracy: 65.6%\n",
      "Validation single digit accuracy: 76.5%\n",
      "Validation image accuracy: 63.9%\n",
      "Minibatch loss at step 2500: 1.215583\n",
      "Minibatch single digit accuracy: 87.6%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 77.0%\n",
      "Validation image accuracy: 65.2%\n",
      "Minibatch loss at step 3000: 1.490098\n",
      "Minibatch single digit accuracy: 80.6%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 79.0%\n",
      "Validation image accuracy: 67.7%\n",
      "Minibatch loss at step 3500: 1.245708\n",
      "Minibatch single digit accuracy: 88.4%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 80.1%\n",
      "Validation image accuracy: 69.1%\n",
      "Minibatch loss at step 4000: 0.485543\n",
      "Minibatch single digit accuracy: 95.8%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 80.3%\n",
      "Validation image accuracy: 69.2%\n",
      "Minibatch loss at step 4500: 0.783474\n",
      "Minibatch single digit accuracy: 92.9%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 70.8%\n",
      "Minibatch loss at step 5000: 0.794374\n",
      "Minibatch single digit accuracy: 93.6%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 81.3%\n",
      "Validation image accuracy: 70.3%\n",
      "Minibatch loss at step 5500: 0.502143\n",
      "Minibatch single digit accuracy: 96.3%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 81.5%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 6000: 0.623720\n",
      "Minibatch single digit accuracy: 93.8%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 71.8%\n",
      "Minibatch loss at step 6500: 0.379734\n",
      "Minibatch single digit accuracy: 98.4%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 71.7%\n",
      "Minibatch loss at step 7000: 0.985863\n",
      "Minibatch single digit accuracy: 92.9%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 82.2%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 7500: 0.647111\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 8000: 0.349782\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.4%\n",
      "Validation image accuracy: 71.6%\n",
      "Minibatch loss at step 8500: 0.779169\n",
      "Minibatch single digit accuracy: 94.6%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 82.6%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 9000: 0.671618\n",
      "Minibatch single digit accuracy: 96.4%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 72.7%\n",
      "Minibatch loss at step 9500: 0.327232\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 10000: 0.569709\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 10500: 0.703843\n",
      "Minibatch single digit accuracy: 96.7%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 72.1%\n",
      "Minibatch loss at step 11000: 0.519143\n",
      "Minibatch single digit accuracy: 97.9%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 82.6%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 11500: 0.376376\n",
      "Minibatch single digit accuracy: 98.5%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 12000: 0.454119\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 73.1%\n",
      "Minibatch loss at step 12500: 0.415269\n",
      "Minibatch single digit accuracy: 97.8%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 13000: 0.526294\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 83.4%\n",
      "Validation image accuracy: 73.0%\n",
      "Minibatch loss at step 13500: 0.407928\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 83.0%\n",
      "Validation image accuracy: 72.6%\n",
      "Minibatch loss at step 14000: 0.395952\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 83.0%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 14500: 0.292382\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 83.3%\n",
      "Validation image accuracy: 73.1%\n",
      "Minibatch loss at step 15000: 0.341074\n",
      "Minibatch single digit accuracy: 100.0%\n",
      "Minibatch image accuracy: 100.0%\n",
      "Validation single digit accuracy: 83.3%\n",
      "Validation image accuracy: 73.1%\n",
      "Test single digit accuracy: 82.2%\n",
      "Test image accuracy: 72.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model v3 - add dropout to all hidden layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_1 :             32 * 32 * 16  \n",
    "lrn                  32 * 32 * 16\n",
    "max pooling:         16 * 16 * 16 \n",
    "\n",
    "conv_2:              16 * 16 * 32 \n",
    "lrn                  16 * 16 * 32\n",
    "max_pooling:         8 * 8 * 32  \n",
    "dropout              0.8\n",
    "\n",
    "conv_3:              8 * 8 * 64\n",
    "lrn                  8 * 8 * 64\n",
    "max pooling:         4 * 4 * 64\n",
    "dropout              0.8\n",
    "\n",
    "fully connect:       1024 * 1024  \n",
    "dropout              0.5  \n",
    "sw_1:                1024 * 11  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[4 * 4 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob, keep_prob2):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        \n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        \n",
    "        pool2 = tf.nn.dropout(pool2, keep_prob2)\n",
    "        \n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        pool3 = tf.nn.dropout(pool3, keep_prob2)\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5, 0.8)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 26.544254\n",
      "Minibatch single digit accuracy: 9.5%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 18.0%\n",
      "Validation image accuracy: 1.2%\n",
      "Minibatch loss at step 500: 6.082138\n",
      "Minibatch single digit accuracy: 15.2%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1000: 4.306312\n",
      "Minibatch single digit accuracy: 39.9%\n",
      "Minibatch image accuracy: 18.8%\n",
      "Validation single digit accuracy: 40.4%\n",
      "Validation image accuracy: 18.9%\n",
      "Minibatch loss at step 1500: 2.673647\n",
      "Minibatch single digit accuracy: 67.9%\n",
      "Minibatch image accuracy: 51.6%\n",
      "Validation single digit accuracy: 64.2%\n",
      "Validation image accuracy: 47.0%\n",
      "Minibatch loss at step 2000: 2.611204\n",
      "Minibatch single digit accuracy: 71.8%\n",
      "Minibatch image accuracy: 56.2%\n",
      "Validation single digit accuracy: 73.3%\n",
      "Validation image accuracy: 59.7%\n",
      "Minibatch loss at step 2500: 1.609107\n",
      "Minibatch single digit accuracy: 85.4%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 76.3%\n",
      "Validation image accuracy: 63.9%\n",
      "Minibatch loss at step 3000: 1.835800\n",
      "Minibatch single digit accuracy: 77.0%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 66.2%\n",
      "Minibatch loss at step 3500: 1.839083\n",
      "Minibatch single digit accuracy: 82.9%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.3%\n",
      "Validation image accuracy: 68.3%\n",
      "Minibatch loss at step 4000: 1.030183\n",
      "Minibatch single digit accuracy: 91.6%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 80.0%\n",
      "Validation image accuracy: 69.7%\n",
      "Minibatch loss at step 4500: 1.287851\n",
      "Minibatch single digit accuracy: 90.0%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 81.0%\n",
      "Validation image accuracy: 70.1%\n",
      "Minibatch loss at step 5000: 1.175619\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 5500: 0.985387\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 71.7%\n",
      "Minibatch loss at step 6000: 1.259826\n",
      "Minibatch single digit accuracy: 90.3%\n",
      "Minibatch image accuracy: 84.4%\n",
      "Validation single digit accuracy: 82.6%\n",
      "Validation image accuracy: 72.3%\n",
      "Minibatch loss at step 6500: 0.960211\n",
      "Minibatch single digit accuracy: 93.5%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 73.0%\n",
      "Minibatch loss at step 7000: 1.526399\n",
      "Minibatch single digit accuracy: 83.1%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 83.7%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 7500: 0.959631\n",
      "Minibatch single digit accuracy: 92.3%\n",
      "Minibatch image accuracy: 84.4%\n",
      "Validation single digit accuracy: 83.5%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 8000: 0.926249\n",
      "Minibatch single digit accuracy: 95.1%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 84.2%\n",
      "Validation image accuracy: 74.6%\n",
      "Minibatch loss at step 8500: 1.420650\n",
      "Minibatch single digit accuracy: 87.8%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 84.1%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 9000: 1.501634\n",
      "Minibatch single digit accuracy: 95.0%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 84.4%\n",
      "Validation image accuracy: 74.8%\n",
      "Minibatch loss at step 9500: 0.805985\n",
      "Minibatch single digit accuracy: 94.2%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 84.3%\n",
      "Validation image accuracy: 74.7%\n",
      "Minibatch loss at step 10000: 0.964842\n",
      "Minibatch single digit accuracy: 96.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 84.6%\n",
      "Validation image accuracy: 74.8%\n",
      "Minibatch loss at step 10500: 1.436502\n",
      "Minibatch single digit accuracy: 94.8%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 84.2%\n",
      "Validation image accuracy: 74.9%\n",
      "Minibatch loss at step 11000: 1.181801\n",
      "Minibatch single digit accuracy: 91.5%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 84.6%\n",
      "Validation image accuracy: 75.6%\n",
      "Minibatch loss at step 11500: 0.569280\n",
      "Minibatch single digit accuracy: 96.2%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 84.7%\n",
      "Validation image accuracy: 75.5%\n",
      "Minibatch loss at step 12000: 0.868071\n",
      "Minibatch single digit accuracy: 95.6%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 85.0%\n",
      "Validation image accuracy: 75.6%\n",
      "Minibatch loss at step 12500: 0.646528\n",
      "Minibatch single digit accuracy: 97.1%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 84.8%\n",
      "Validation image accuracy: 75.5%\n",
      "Minibatch loss at step 13000: 1.315371\n",
      "Minibatch single digit accuracy: 96.5%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 84.9%\n",
      "Validation image accuracy: 75.8%\n",
      "Minibatch loss at step 13500: 0.909154\n",
      "Minibatch single digit accuracy: 95.1%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 85.0%\n",
      "Validation image accuracy: 75.9%\n",
      "Minibatch loss at step 14000: 1.123146\n",
      "Minibatch single digit accuracy: 96.4%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 14500: 0.805401\n",
      "Minibatch single digit accuracy: 96.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 15000: 0.658818\n",
      "Minibatch single digit accuracy: 98.6%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.5%\n",
      "Validation image accuracy: 76.3%\n",
      "Minibatch loss at step 15500: 0.753241\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 16000: 0.775419\n",
      "Minibatch single digit accuracy: 96.2%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.1%\n",
      "Minibatch loss at step 16500: 0.794621\n",
      "Minibatch single digit accuracy: 97.0%\n",
      "Minibatch image accuracy: 92.2%\n",
      "Validation single digit accuracy: 85.3%\n",
      "Validation image accuracy: 76.0%\n",
      "Minibatch loss at step 17000: 0.543207\n",
      "Minibatch single digit accuracy: 99.2%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 17500: 0.939861\n",
      "Minibatch single digit accuracy: 96.6%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 85.9%\n",
      "Validation image accuracy: 76.7%\n",
      "Minibatch loss at step 18000: 1.012314\n",
      "Minibatch single digit accuracy: 97.4%\n",
      "Minibatch image accuracy: 93.8%\n",
      "Validation single digit accuracy: 85.8%\n",
      "Validation image accuracy: 76.7%\n",
      "Minibatch loss at step 18500: 0.597680\n",
      "Minibatch single digit accuracy: 99.3%\n",
      "Minibatch image accuracy: 98.4%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.2%\n",
      "Minibatch loss at step 19000: 0.569003\n",
      "Minibatch single digit accuracy: 97.7%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.4%\n",
      "Validation image accuracy: 76.3%\n",
      "Minibatch loss at step 19500: 0.598698\n",
      "Minibatch single digit accuracy: 97.1%\n",
      "Minibatch image accuracy: 95.3%\n",
      "Validation single digit accuracy: 85.9%\n",
      "Validation image accuracy: 76.8%\n",
      "Minibatch loss at step 20000: 0.691507\n",
      "Minibatch single digit accuracy: 97.7%\n",
      "Minibatch image accuracy: 96.9%\n",
      "Validation single digit accuracy: 85.8%\n",
      "Validation image accuracy: 76.6%\n",
      "Test single digit accuracy: 84.8%\n",
      "Test image accuracy: 75.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model v4 - change dropout on cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "    def max_pooling(data):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size, patch_size, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "    \n",
    "    # func1 layer 4\n",
    "    layer4_weights = get_weight_variable('FC_W1',[4 * 4 * depth3, num_hidden])\n",
    "    layer4_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob, keep_prob2):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1) # 16 * 16 * depth1\n",
    "        \n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2) # 8 * 8 * depth2\n",
    "        \n",
    "        pool2 = tf.nn.dropout(pool2, keep_prob2)\n",
    "        \n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3) # 4 * 4 * depth3\n",
    "        \n",
    "        pool3 = tf.nn.dropout(pool3, keep_prob2)\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden4 = tf.nn.relu(tf.matmul(pool3_flat, layer4_weights) + layer4_biases)\n",
    "        hidden4_drop = tf.nn.dropout(hidden4, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden4_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden4_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden4_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden4_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden4_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5, 0.5)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 17.567846\n",
      "Minibatch single digit accuracy: 12.2%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 500: 6.044502\n",
      "Minibatch single digit accuracy: 15.2%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 19.5%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1000: 5.449240\n",
      "Minibatch single digit accuracy: 21.7%\n",
      "Minibatch image accuracy: 7.8%\n",
      "Validation single digit accuracy: 19.3%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1500: 4.672151\n",
      "Minibatch single digit accuracy: 37.1%\n",
      "Minibatch image accuracy: 12.5%\n",
      "Validation single digit accuracy: 33.6%\n",
      "Validation image accuracy: 12.7%\n",
      "Minibatch loss at step 2000: 4.028084\n",
      "Minibatch single digit accuracy: 54.9%\n",
      "Minibatch image accuracy: 42.2%\n",
      "Validation single digit accuracy: 56.8%\n",
      "Validation image accuracy: 40.1%\n",
      "Minibatch loss at step 2500: 2.689013\n",
      "Minibatch single digit accuracy: 70.8%\n",
      "Minibatch image accuracy: 53.1%\n",
      "Validation single digit accuracy: 62.7%\n",
      "Validation image accuracy: 47.0%\n",
      "Minibatch loss at step 3000: 2.929991\n",
      "Minibatch single digit accuracy: 71.9%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 67.7%\n",
      "Validation image accuracy: 53.0%\n",
      "Minibatch loss at step 3500: 3.014989\n",
      "Minibatch single digit accuracy: 76.0%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 71.2%\n",
      "Validation image accuracy: 57.4%\n",
      "Minibatch loss at step 4000: 1.784424\n",
      "Minibatch single digit accuracy: 81.5%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 71.5%\n",
      "Validation image accuracy: 58.2%\n",
      "Minibatch loss at step 4500: 2.358316\n",
      "Minibatch single digit accuracy: 84.3%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 74.2%\n",
      "Validation image accuracy: 61.8%\n",
      "Minibatch loss at step 5000: 2.577543\n",
      "Minibatch single digit accuracy: 78.6%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 75.4%\n",
      "Validation image accuracy: 63.1%\n",
      "Minibatch loss at step 5500: 2.091293\n",
      "Minibatch single digit accuracy: 85.9%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 76.2%\n",
      "Validation image accuracy: 64.7%\n",
      "Minibatch loss at step 6000: 2.282319\n",
      "Minibatch single digit accuracy: 81.4%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 77.4%\n",
      "Validation image accuracy: 65.5%\n",
      "Minibatch loss at step 6500: 1.843521\n",
      "Minibatch single digit accuracy: 87.1%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 77.8%\n",
      "Validation image accuracy: 66.7%\n",
      "Minibatch loss at step 7000: 2.838985\n",
      "Minibatch single digit accuracy: 70.1%\n",
      "Minibatch image accuracy: 56.2%\n",
      "Validation single digit accuracy: 78.0%\n",
      "Validation image accuracy: 66.8%\n",
      "Minibatch loss at step 7500: 1.989663\n",
      "Minibatch single digit accuracy: 80.4%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 78.8%\n",
      "Validation image accuracy: 67.8%\n",
      "Minibatch loss at step 8000: 2.033044\n",
      "Minibatch single digit accuracy: 82.5%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 78.6%\n",
      "Validation image accuracy: 67.4%\n",
      "Minibatch loss at step 8500: 2.340281\n",
      "Minibatch single digit accuracy: 79.6%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 79.6%\n",
      "Validation image accuracy: 69.0%\n",
      "Minibatch loss at step 9000: 2.525029\n",
      "Minibatch single digit accuracy: 77.0%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 79.5%\n",
      "Validation image accuracy: 68.7%\n",
      "Minibatch loss at step 9500: 1.682556\n",
      "Minibatch single digit accuracy: 86.3%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 79.7%\n",
      "Validation image accuracy: 69.1%\n",
      "Minibatch loss at step 10000: 2.165486\n",
      "Minibatch single digit accuracy: 82.8%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 80.8%\n",
      "Validation image accuracy: 70.0%\n",
      "Minibatch loss at step 10500: 2.566441\n",
      "Minibatch single digit accuracy: 78.4%\n",
      "Minibatch image accuracy: 59.4%\n",
      "Validation single digit accuracy: 80.1%\n",
      "Validation image accuracy: 69.6%\n",
      "Minibatch loss at step 11000: 2.522482\n",
      "Minibatch single digit accuracy: 78.0%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 80.6%\n",
      "Validation image accuracy: 70.2%\n",
      "Minibatch loss at step 11500: 1.332847\n",
      "Minibatch single digit accuracy: 89.3%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 80.7%\n",
      "Validation image accuracy: 70.9%\n",
      "Minibatch loss at step 12000: 1.648906\n",
      "Minibatch single digit accuracy: 87.5%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 70.7%\n",
      "Minibatch loss at step 12500: 1.544498\n",
      "Minibatch single digit accuracy: 88.4%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 13000: 1.812610\n",
      "Minibatch single digit accuracy: 83.2%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 13500: 1.926704\n",
      "Minibatch single digit accuracy: 81.9%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 80.8%\n",
      "Validation image accuracy: 70.8%\n",
      "Minibatch loss at step 14000: 1.795984\n",
      "Minibatch single digit accuracy: 84.9%\n",
      "Minibatch image accuracy: 70.3%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 14500: 2.010885\n",
      "Minibatch single digit accuracy: 82.1%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 72.2%\n",
      "Minibatch loss at step 15000: 1.635014\n",
      "Minibatch single digit accuracy: 88.7%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 15500: 1.828920\n",
      "Minibatch single digit accuracy: 84.8%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 82.3%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 16000: 1.811475\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 72.0%\n",
      "Minibatch loss at step 16500: 1.520308\n",
      "Minibatch single digit accuracy: 85.2%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 82.0%\n",
      "Validation image accuracy: 72.5%\n",
      "Minibatch loss at step 17000: 1.338222\n",
      "Minibatch single digit accuracy: 89.6%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 73.2%\n",
      "Minibatch loss at step 17500: 2.136766\n",
      "Minibatch single digit accuracy: 81.4%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 82.5%\n",
      "Validation image accuracy: 73.2%\n",
      "Minibatch loss at step 18000: 2.500756\n",
      "Minibatch single digit accuracy: 78.2%\n",
      "Minibatch image accuracy: 62.5%\n",
      "Validation single digit accuracy: 82.4%\n",
      "Validation image accuracy: 72.8%\n",
      "Minibatch loss at step 18500: 1.536660\n",
      "Minibatch single digit accuracy: 91.4%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 82.8%\n",
      "Validation image accuracy: 73.2%\n",
      "Minibatch loss at step 19000: 1.709830\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 73.1%\n",
      "Minibatch loss at step 19500: 1.500337\n",
      "Minibatch single digit accuracy: 89.2%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 82.9%\n",
      "Validation image accuracy: 73.5%\n",
      "Minibatch loss at step 20000: 1.677698\n",
      "Minibatch single digit accuracy: 85.5%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 73.3%\n",
      "Test single digit accuracy: 82.6%\n",
      "Test image accuracy: 73.5%\n",
      "Model saved in file: 3cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"3cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored!\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1.707028\n",
      "Minibatch single digit accuracy: 85.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 82.7%\n",
      "Validation image accuracy: 73.3%\n",
      "Minibatch loss at step 500: 1.836549\n",
      "Minibatch single digit accuracy: 85.5%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 1000: 1.508532\n",
      "Minibatch single digit accuracy: 86.7%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 1500: 1.532207\n",
      "Minibatch single digit accuracy: 90.0%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 83.0%\n",
      "Validation image accuracy: 73.7%\n",
      "Minibatch loss at step 2000: 1.768131\n",
      "Minibatch single digit accuracy: 86.6%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 2500: 1.279365\n",
      "Minibatch single digit accuracy: 93.4%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 3000: 1.665398\n",
      "Minibatch single digit accuracy: 84.9%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 83.3%\n",
      "Validation image accuracy: 74.1%\n",
      "Minibatch loss at step 3500: 1.735253\n",
      "Minibatch single digit accuracy: 87.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 83.4%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 4000: 1.263773\n",
      "Minibatch single digit accuracy: 93.3%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 4500: 1.327173\n",
      "Minibatch single digit accuracy: 92.1%\n",
      "Minibatch image accuracy: 85.9%\n",
      "Validation single digit accuracy: 83.1%\n",
      "Validation image accuracy: 73.8%\n",
      "Minibatch loss at step 5000: 1.593463\n",
      "Minibatch single digit accuracy: 90.0%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 5500: 1.241238\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.5%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 6000: 1.544100\n",
      "Minibatch single digit accuracy: 85.5%\n",
      "Minibatch image accuracy: 73.4%\n",
      "Validation single digit accuracy: 83.4%\n",
      "Validation image accuracy: 74.3%\n",
      "Minibatch loss at step 6500: 1.042105\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 89.1%\n",
      "Validation single digit accuracy: 83.7%\n",
      "Validation image accuracy: 74.6%\n",
      "Minibatch loss at step 7000: 2.115245\n",
      "Minibatch single digit accuracy: 81.2%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 83.2%\n",
      "Validation image accuracy: 74.0%\n",
      "Minibatch loss at step 7500: 1.539744\n",
      "Minibatch single digit accuracy: 86.7%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.5%\n",
      "Minibatch loss at step 8000: 1.200860\n",
      "Minibatch single digit accuracy: 92.3%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 83.8%\n",
      "Validation image accuracy: 74.7%\n",
      "Minibatch loss at step 8500: 1.881015\n",
      "Minibatch single digit accuracy: 84.4%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.3%\n",
      "Minibatch loss at step 9000: 1.979492\n",
      "Minibatch single digit accuracy: 85.6%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 83.6%\n",
      "Validation image accuracy: 74.4%\n",
      "Minibatch loss at step 9500: 1.553418\n",
      "Minibatch single digit accuracy: 94.2%\n",
      "Minibatch image accuracy: 90.6%\n",
      "Validation single digit accuracy: 83.8%\n",
      "Validation image accuracy: 74.7%\n",
      "Minibatch loss at step 10000: 1.535608\n",
      "Minibatch single digit accuracy: 88.8%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 83.7%\n",
      "Validation image accuracy: 74.5%\n",
      "Test single digit accuracy: 83.7%\n",
      "Test image accuracy: 74.9%\n",
      "Model saved in file: 3cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    # If you want to restore model\n",
    "    saver.restore(session, \"3cnn.ckpt\")\n",
    "    print(\"Model restored!\")\n",
    "\n",
    "#     tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"3cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add one conv layer - (Abandoned.  RAM runs out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5 # conv kernel size\n",
    "patch_size2 = 5\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "# depth3 = 48\n",
    "depth3 = 128\n",
    "num_hidden = 64\n",
    "\n",
    "image_size = 32\n",
    "num_labels = 11 \n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    def get_weight_variable(name, shape):\n",
    "        return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(1.0, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(data, weight):\n",
    "        # strides [1, x_movement, y_movement, 1]\n",
    "        return tf.nn.conv2d(data, weight, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "\n",
    "    def max_pooling(data, strides):\n",
    "        return tf.nn.max_pool(data, ksize = [1, 2, 2, 1], strides = strides, padding = 'SAME')\n",
    "    \n",
    "    def get_label_wb(weight_name):\n",
    "        weights = tf.get_variable(weight_name, shape=[num_hidden, num_labels],\\\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "        return weights, biases \n",
    "    \n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 6))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    \n",
    "    # Varibles\n",
    "    # conv1 layer 1\n",
    "    layer1_weights = get_weight_variable('CNN_W1', [patch_size, patch_size, num_channels, depth1])\n",
    "    layer1_biases = bias_variable([depth1]) # 16\n",
    "    # conv2 layer 2\n",
    "    layer2_weights = get_weight_variable('CNN_W2', [patch_size, patch_size, depth1, depth2])\n",
    "    layer2_biases = bias_variable([depth2]) # 32\n",
    "    # conv3 layer 3\n",
    "    layer3_weights = get_weight_variable('CNN_W3', [patch_size2, patch_size2, depth2, depth3])\n",
    "    layer3_biases = bias_variable([depth3]) # 64\n",
    "#     # conv4 layer 4\n",
    "#     layer4_weights = get_weight_variable('CNN_W4', [patch_size2, patch_size2, depth3, depth4])\n",
    "#     layer4_biases = bias_variable([depth4]) # 64\n",
    "    \n",
    "    # func1 layer 5\n",
    "    layer5_weights = get_weight_variable('FC_W1',[1152, num_hidden])\n",
    "    layer5_biases = bias_variable([num_hidden])\n",
    "    \n",
    "    # locally connected layers\n",
    "    s1_w, s1_b = get_label_wb('S1_W')\n",
    "    s2_w, s2_b = get_label_wb('S2_W')\n",
    "    s3_w, s3_b = get_label_wb('S3_W')\n",
    "    s4_w, s4_b = get_label_wb('S4_W')\n",
    "    s5_w, s5_b = get_label_wb('S5_W')\n",
    "    \n",
    "    sw = [s1_w, s2_w, s3_w, s4_w, s5_w]\n",
    "    \n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    \n",
    "    def model(dataset, keep_prob, keep_prob2):\n",
    "        # conv1 layer 1\n",
    "        hidden1 = tf.nn.relu(conv2d(dataset, layer1_weights) + layer1_biases) # 32 * 32 * depth1\n",
    "        hidden1 = tf.nn.local_response_normalization(hidden1)\n",
    "        pool1 = max_pooling(hidden1, [1, 2, 2, 1]) # 16 * 16 * depth1\n",
    "        \n",
    "        # conv2 layer 2\n",
    "        hidden2 = tf.nn.relu(conv2d(pool1, layer2_weights) + layer2_biases) # 16 * 16 * depth2\n",
    "        hidden2 = tf.nn.local_response_normalization(hidden2)\n",
    "        pool2 = max_pooling(hidden2, [1, 1, 1, 1]) # 8 * 8 * depth2\n",
    "        pool2 = tf.nn.dropout(pool2, keep_prob2)\n",
    "        \n",
    "        # conv3 layer 3\n",
    "        hidden3 = tf.nn.relu(conv2d(pool2, layer3_weights) + layer3_biases) # 8 * 8 * depth3\n",
    "        hidden3 = tf.nn.local_response_normalization(hidden3)\n",
    "        pool3 = max_pooling(hidden3, [1, 2, 2, 1]) # 4 * 4 * depth3\n",
    "#         pool3 = tf.nn.dropout(pool3, keep_prob2)\n",
    "        \n",
    "#         # conv3 layer 3\n",
    "#         hidden4 = tf.nn.relu(conv2d(pool3, layer4_weights) + layer4_biases) # 8 * 8 * depth3\n",
    "#         hidden4 = tf.nn.local_response_normalization(hidden4)\n",
    "#         pool4 = max_pooling(hidden4, [1, 2, 2, 1]) # 4 * 4 * depth3\n",
    "#         pool4 = tf.nn.dropout(pool4, keep_prob2)\n",
    "        \n",
    "        shape = pool3.get_shape().as_list()\n",
    "        pool3_flat = tf.reshape(pool3, [shape[0], shape[1] * shape[2] * shape[3]]) # 1024\n",
    "        \n",
    "        # func1 layer 4\n",
    "        hidden5 = tf.nn.relu(tf.matmul(pool3_flat, layer5_weights) + layer5_biases)\n",
    "        hidden5_drop = tf.nn.dropout(hidden5, keep_prob)\n",
    "\n",
    "        logits_1 = tf.matmul(hidden5_drop, s1_w) + s1_b\n",
    "        logits_2 = tf.matmul(hidden5_drop, s2_w) + s2_b\n",
    "        logits_3 = tf.matmul(hidden5_drop, s3_w) + s3_b\n",
    "        logits_4 = tf.matmul(hidden5_drop, s4_w) + s4_b\n",
    "        logits_5 = tf.matmul(hidden5_drop, s5_w) + s5_b\n",
    "        \n",
    "        return [logits_1, logits_2, logits_3, logits_4, logits_5]\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_dataset, 0.5, 0.8)\n",
    "    \n",
    "    loss_per_digit = [tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits[i],\n",
    "                            tf_train_labels[:,i+1]\n",
    "                        )) + beta_regul * tf.nn.l2_loss(sw[i])\n",
    "                       for i in range(5)]\n",
    "    \n",
    "    loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.001, global_step, 1000, 0.90, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    def prediction_softmax(dataset):\n",
    "        prediction = tf.pack([\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[0]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[1]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[2]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[3]),\n",
    "            tf.nn.softmax(model(dataset, 1.0, 1.0)[4])])\n",
    "        return prediction\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = prediction_softmax(tf_train_dataset)\n",
    "    valid_prediction = prediction_softmax(tf_valid_dataset)             \n",
    "    test_prediction = prediction_softmax(tf_test_dataset)\n",
    "    \n",
    "    # Save Model \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 21.580215\n",
      "Minibatch single digit accuracy: 2.7%\n",
      "Minibatch image accuracy: 0.0%\n",
      "Validation single digit accuracy: 6.9%\n",
      "Validation image accuracy: 0.0%\n",
      "Minibatch loss at step 500: 6.046764\n",
      "Minibatch single digit accuracy: 12.4%\n",
      "Minibatch image accuracy: 3.1%\n",
      "Validation single digit accuracy: 19.1%\n",
      "Validation image accuracy: 3.6%\n",
      "Minibatch loss at step 1000: 5.019938\n",
      "Minibatch single digit accuracy: 33.6%\n",
      "Minibatch image accuracy: 10.9%\n",
      "Validation single digit accuracy: 33.9%\n",
      "Validation image accuracy: 13.1%\n",
      "Minibatch loss at step 1500: 4.056178\n",
      "Minibatch single digit accuracy: 54.3%\n",
      "Minibatch image accuracy: 34.4%\n",
      "Validation single digit accuracy: 48.2%\n",
      "Validation image accuracy: 28.1%\n",
      "Minibatch loss at step 2000: 3.900603\n",
      "Minibatch single digit accuracy: 50.7%\n",
      "Minibatch image accuracy: 34.4%\n",
      "Validation single digit accuracy: 56.2%\n",
      "Validation image accuracy: 37.0%\n",
      "Minibatch loss at step 2500: 3.121350\n",
      "Minibatch single digit accuracy: 67.2%\n",
      "Minibatch image accuracy: 45.3%\n",
      "Validation single digit accuracy: 61.0%\n",
      "Validation image accuracy: 43.6%\n",
      "Minibatch loss at step 3000: 2.897475\n",
      "Minibatch single digit accuracy: 67.6%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 65.7%\n",
      "Validation image accuracy: 50.5%\n",
      "Minibatch loss at step 3500: 2.975567\n",
      "Minibatch single digit accuracy: 67.1%\n",
      "Minibatch image accuracy: 51.6%\n",
      "Validation single digit accuracy: 70.5%\n",
      "Validation image accuracy: 56.6%\n",
      "Minibatch loss at step 4000: 2.281278\n",
      "Minibatch single digit accuracy: 79.0%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 71.6%\n",
      "Validation image accuracy: 58.0%\n",
      "Minibatch loss at step 4500: 2.070471\n",
      "Minibatch single digit accuracy: 77.9%\n",
      "Minibatch image accuracy: 67.2%\n",
      "Validation single digit accuracy: 73.8%\n",
      "Validation image accuracy: 61.0%\n",
      "Minibatch loss at step 5000: 2.151306\n",
      "Minibatch single digit accuracy: 74.3%\n",
      "Minibatch image accuracy: 60.9%\n",
      "Validation single digit accuracy: 74.4%\n",
      "Validation image accuracy: 61.4%\n",
      "Minibatch loss at step 5500: 1.939853\n",
      "Minibatch single digit accuracy: 78.5%\n",
      "Minibatch image accuracy: 59.4%\n",
      "Validation single digit accuracy: 75.0%\n",
      "Validation image accuracy: 62.2%\n",
      "Minibatch loss at step 6000: 2.011651\n",
      "Minibatch single digit accuracy: 79.3%\n",
      "Minibatch image accuracy: 65.6%\n",
      "Validation single digit accuracy: 76.3%\n",
      "Validation image accuracy: 63.9%\n",
      "Minibatch loss at step 6500: 1.661243\n",
      "Minibatch single digit accuracy: 83.9%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 77.9%\n",
      "Validation image accuracy: 65.4%\n",
      "Minibatch loss at step 7000: 2.375058\n",
      "Minibatch single digit accuracy: 76.0%\n",
      "Minibatch image accuracy: 64.1%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 66.7%\n",
      "Minibatch loss at step 7500: 1.886878\n",
      "Minibatch single digit accuracy: 80.4%\n",
      "Minibatch image accuracy: 68.8%\n",
      "Validation single digit accuracy: 78.1%\n",
      "Validation image accuracy: 66.8%\n",
      "Minibatch loss at step 8000: 1.759828\n",
      "Minibatch single digit accuracy: 81.8%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 78.3%\n",
      "Validation image accuracy: 67.0%\n",
      "Minibatch loss at step 8500: 2.208157\n",
      "Minibatch single digit accuracy: 81.0%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.0%\n",
      "Validation image accuracy: 68.0%\n",
      "Minibatch loss at step 9000: 2.297939\n",
      "Minibatch single digit accuracy: 79.1%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.3%\n",
      "Validation image accuracy: 68.2%\n",
      "Minibatch loss at step 9500: 1.511883\n",
      "Minibatch single digit accuracy: 91.4%\n",
      "Minibatch image accuracy: 84.4%\n",
      "Validation single digit accuracy: 79.3%\n",
      "Validation image accuracy: 68.3%\n",
      "Minibatch loss at step 10000: 1.828559\n",
      "Minibatch single digit accuracy: 85.1%\n",
      "Minibatch image accuracy: 71.9%\n",
      "Validation single digit accuracy: 79.8%\n",
      "Validation image accuracy: 68.9%\n",
      "Test single digit accuracy: 80.6%\n",
      "Test image accuracy: 70.6%\n",
      "Model saved in file: 5cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "#     save_path = saver.save(session, \"CNN5.ckpt\")\n",
    "#     print(\"Model restored to:\", save_path)  \n",
    "    \n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"5cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored!\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1.978281\n",
      "Minibatch single digit accuracy: 85.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 79.8%\n",
      "Validation image accuracy: 68.9%\n",
      "Minibatch loss at step 500: 2.169738\n",
      "Minibatch single digit accuracy: 86.9%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 80.0%\n",
      "Validation image accuracy: 69.2%\n",
      "Minibatch loss at step 1000: 2.131892\n",
      "Minibatch single digit accuracy: 83.2%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 80.0%\n",
      "Validation image accuracy: 69.5%\n",
      "Minibatch loss at step 1500: 1.469676\n",
      "Minibatch single digit accuracy: 86.4%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 79.9%\n",
      "Validation image accuracy: 69.7%\n",
      "Minibatch loss at step 2000: 2.054354\n",
      "Minibatch single digit accuracy: 85.2%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 80.4%\n",
      "Validation image accuracy: 70.3%\n",
      "Minibatch loss at step 2500: 1.332862\n",
      "Minibatch single digit accuracy: 94.9%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 80.3%\n",
      "Validation image accuracy: 69.9%\n",
      "Minibatch loss at step 3000: 2.060459\n",
      "Minibatch single digit accuracy: 82.7%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 80.3%\n",
      "Validation image accuracy: 70.2%\n",
      "Minibatch loss at step 3500: 1.636135\n",
      "Minibatch single digit accuracy: 87.0%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 80.6%\n",
      "Validation image accuracy: 70.2%\n",
      "Minibatch loss at step 4000: 1.101616\n",
      "Minibatch single digit accuracy: 91.6%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 80.5%\n",
      "Validation image accuracy: 70.5%\n",
      "Minibatch loss at step 4500: 1.563582\n",
      "Minibatch single digit accuracy: 88.6%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 81.0%\n",
      "Validation image accuracy: 71.1%\n",
      "Minibatch loss at step 5000: 1.462399\n",
      "Minibatch single digit accuracy: 89.3%\n",
      "Minibatch image accuracy: 79.7%\n",
      "Validation single digit accuracy: 80.9%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 5500: 1.287081\n",
      "Minibatch single digit accuracy: 91.9%\n",
      "Minibatch image accuracy: 82.8%\n",
      "Validation single digit accuracy: 81.2%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 6000: 1.548199\n",
      "Minibatch single digit accuracy: 88.3%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 80.7%\n",
      "Validation image accuracy: 70.7%\n",
      "Minibatch loss at step 6500: 1.273672\n",
      "Minibatch single digit accuracy: 89.5%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.2%\n",
      "Minibatch loss at step 7000: 2.028769\n",
      "Minibatch single digit accuracy: 82.5%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 7500: 1.574272\n",
      "Minibatch single digit accuracy: 84.6%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.1%\n",
      "Validation image accuracy: 71.3%\n",
      "Minibatch loss at step 8000: 1.520929\n",
      "Minibatch single digit accuracy: 86.7%\n",
      "Minibatch image accuracy: 78.1%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.5%\n",
      "Minibatch loss at step 8500: 1.927362\n",
      "Minibatch single digit accuracy: 83.7%\n",
      "Minibatch image accuracy: 76.6%\n",
      "Validation single digit accuracy: 81.4%\n",
      "Validation image accuracy: 71.4%\n",
      "Minibatch loss at step 9000: 1.756405\n",
      "Minibatch single digit accuracy: 87.1%\n",
      "Minibatch image accuracy: 81.2%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 71.8%\n",
      "Minibatch loss at step 9500: 1.507004\n",
      "Minibatch single digit accuracy: 93.5%\n",
      "Minibatch image accuracy: 87.5%\n",
      "Validation single digit accuracy: 81.6%\n",
      "Validation image accuracy: 71.8%\n",
      "Minibatch loss at step 10000: 1.721653\n",
      "Minibatch single digit accuracy: 88.1%\n",
      "Minibatch image accuracy: 75.0%\n",
      "Validation single digit accuracy: 81.8%\n",
      "Validation image accuracy: 71.8%\n",
      "Test single digit accuracy: 82.3%\n",
      "Test image accuracy: 72.5%\n",
      "Model saved in file: 5cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    # If you want to restore model\n",
    "    saver.restore(session, \"5cnn.ckpt\")\n",
    "    print(\"Model restored!\")\n",
    "    \n",
    "#     tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch single digit accuracy: %.1f%%' % accuracy_single(predictions, batch_labels))\n",
    "            print('Minibatch image accuracy: %.1f%%' % accuracy_multi(predictions, batch_labels))\n",
    "            print('Validation single digit accuracy: %.1f%%' % accuracy_single(valid_prediction.eval(), valid_labels))\n",
    "            print('Validation image accuracy: %.1f%%' % accuracy_multi(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test single digit accuracy: %.1f%%' % accuracy_single(test_prediction.eval(), test_labels))\n",
    "    print('Test image accuracy: %.1f%%' % accuracy_multi(test_prediction.eval(), test_labels))\n",
    "    \n",
    "    save_path = saver.save(session, \"5cnn.ckpt\")\n",
    "    print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
